# Local-pdf-Llama-Chatbot

A simple, fast, and fully **local chatbot** that lets you **talk to any PDF** using [Ollama](https://ollama.com), [LangChain](https://www.langchain.com/), and **LLaMA3** â€” with document-aware retrieval powered by Chroma and embeddings from `mxbai-embed-large`.

It shows how to:
- ğŸ§  Run a Retrieval-Augmented Generation (RAG) pipeline
- ğŸ“„ Process PDFs and extract metadata
- ğŸ’¬ Build a conversational interface for querying local files
- ğŸ”’ Work completely offline after setup

---

## ğŸš€ Getting Started

### 1. Set up the environment

```bash
conda create --name new_env python=3.10 -y
conda activate new_env
conda install python -y
```

### 2. Install Ollama

```bash
curl -fsSL https://ollama.com/install.sh | sh
```

Pull the required models:

```bash
ollama pull llama3
ollama pull mxbai-embed-large
```

### 3. Install Python Dependencies
```bash
pip install langchain langchain-ollama ollama
pip install langchain-chroma langchain-community
pip install unstructured pypdf
# or install the full extra dependencies
pip install "unstructured[pdf]"
```


## ğŸ’¬ Run the Chatbot

```bash
python main_ollama.py
```

### Example questions

```bash
Welcome to DocBot!     Type 'exit', 'exit', 'bye' to stop.
You: hi
DocBot:  I'm happy to help! However, I don't see any specific question or PDF information provided. Could you please clarify what you would like me to answer?
```

## ğŸ“ Project Structure
.
â”œâ”€â”€ main_ollama.py          # Chat loop: ask questions about any PDF
â”œâ”€â”€ input_pdfs.py           # Loads, splits, indexes PDFs with metadata
â”œâ”€â”€ pdfs/                   # Drop your PDF files here


